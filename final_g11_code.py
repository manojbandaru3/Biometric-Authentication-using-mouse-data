# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fY404TbObmUmBI7mCPErUFi88u4ZoCTI
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.mixture import GaussianMixture
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
import numpy as np
import extractor
import os
import pickle
from statistics import mean

#features_extraction
X_Rajesh= features(24,"group11/data/authenticated/Rajesh/log")
X_Manoj= features(26,"group11/data/authenticated/Manoj/")
X_Daiveek= features(18,"group11/data/authenticated/Daiveek/")
X_Sudheer= features(26,"group11/data/authenticated/Sudheer/log")
X_Vamsi= features(68,"group11/data/authenticated/Vamsi/")
X_imposter=features(35,"group11/data/imposter/")

#importing Data from pickle files since we have already extracted features and stored in .txt pickle files to save time
pickle_off = open ("group11/feature_extracted/rajesha.txt", "rb")
X_Rajesh= pickle.load(pickle_off)

pickle_off = open ("group11/feature_extracted/daiveeka.txt", "rb")
X_Daiveek = pickle.load(pickle_off)

pickle_off = open ("group11/feature_extracted/manoja.txt", "rb")
X_Manoj= pickle.load(pickle_off)

pickle_off = open ("group11/feature_extracted/sudheera.txt", "rb")
X_Sudheer = pickle.load(pickle_off)

pickle_off = open ("group11/feature_extracted/sudheera.txt", "rb")
X_Sudheer = pickle.load(pickle_off)

pickle_off = open ("group11/feature_extracted/vamsia.txt", "rb")
X_Vamsi= pickle.load(pickle_off)

X_imposter=np.load('group11/feature_extracted/imposter.npy')

#printing sizes of individual dataset
print(X_Rajesh.shape)
print(X_Daiveek.shape)
print(X_Manoj.shape)
print(X_Sudheer.shape)
print(X_Vamsi.shape)
print(X_imposter.shape)

#combining all the authenticated users into single variable and define corresponding y variables for imposter and authenticated users
X_auth_final=np.concatenate((X_Rajesh,X_Manoj,X_Vamsi,X_Sudheer,X_Daiveek),axis = 0)
X_imposter=X_imposter
y_auth_final=np.zeros(len(X_auth_final))
y_imposter=np.ones(len(X_imposter))
print(X_auth_final.shape)
print(y_auth_final.shape)
print(X_imposter.shape)
print(y_imposter.shape)

#concatenate imposter and authenticated data for feature selection
X=np.concatenate((X_auth_final,X_imposter),axis=0)
y=np.concatenate((y_auth_final,y_imposter),axis=0)
print(X.shape)
print(y.shape)

#using SFS technique for feature selection
knn = KNeighborsClassifier(n_neighbors=63)
sfs1 = SFS(knn,
           k_features=5,
           forward=True,
           floating=False,
           scoring='accuracy',
           cv=4)

#fitting X,y
sfs1 = sfs1.fit(X, y)
print(sfs1.k_feature_idx_)

#combining all data in to a variable with only selected features
X=[X_Rajesh[:,(0,1,2,3,60)],X_Manoj[:,(0,1,2,3,60)],X_Vamsi[:,(0,1,2,3,60)],X_Sudheer[:,(0,1,2,3,60)],X_Daiveek[:,(0,1,2,3,60)],X_imposter[:,(0,1,2,3,60)]]

#partioning individual datasets in to 5 parts for each user 
Train_part1=[]
Train_part2=[]
Train_part3=[]
Train_part4=[]
Train_part5=[]
for i in range(6):
  Training_Data = X[i]
  delta = int(Training_Data.shape[0]/5)
  Train_part1.append(Training_Data[0:delta,:])
  Train_part2.append(Training_Data[delta:2*delta,:])
  Train_part3.append(Training_Data[2*delta:3*delta,:])
  Train_part4.append(Training_Data[3*delta:4*delta,:])
  Train_part5.append(Training_Data[4*delta:,:])

#Fold-1 cross Validation

X_test=Train_part1
X_train0=np.concatenate((Train_part2[0],Train_part3[0],Train_part4[0],Train_part5[0]),axis=0)
X_train1=np.concatenate((Train_part2[1],Train_part3[1],Train_part4[1],Train_part5[1]),axis=0)
X_train2=np.concatenate((Train_part2[2],Train_part3[2],Train_part4[2],Train_part5[2]),axis=0)
X_train3=np.concatenate((Train_part2[3],Train_part3[3],Train_part4[3],Train_part5[3]),axis=0)
X_train4=np.concatenate((Train_part2[4],Train_part3[4],Train_part4[4],Train_part5[4]),axis=0)
X_train5=np.concatenate((Train_part2[5],Train_part3[5],Train_part4[5],Train_part5[5]),axis=0)
X_train=np.concatenate((X_train0,X_train1,X_train2,X_train3,X_train4,X_train5),axis=0)
gmm = GaussianMixture(n_components=2)
gmm.fit(X_train)

print("Training Accuracies")
labels_rajesh = gmm.predict(X_train0)
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_train1)
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_train2)
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_train3)
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_train4)
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_train5)
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average training accuracy:",mean(x))
print("end")
print()

print("Test Accuracies")
labels_rajesh = gmm.predict(X_test[0])
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_test[1])
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_test[2])
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_test[3])
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_test[4])
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_test[5])
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average test accuracy:",mean(x))
print("end")

#Fold-2 cross validation

X_test=Train_part2
X_train0=np.concatenate((Train_part1[0],Train_part3[0],Train_part4[0],Train_part5[0]),axis=0)
X_train1=np.concatenate((Train_part1[1],Train_part3[1],Train_part4[1],Train_part5[1]),axis=0)
X_train2=np.concatenate((Train_part1[2],Train_part3[2],Train_part4[2],Train_part5[2]),axis=0)
X_train3=np.concatenate((Train_part1[3],Train_part3[3],Train_part4[3],Train_part5[3]),axis=0)
X_train4=np.concatenate((Train_part1[4],Train_part3[4],Train_part4[4],Train_part5[4]),axis=0)
X_train5=np.concatenate((Train_part1[5],Train_part3[5],Train_part4[5],Train_part5[5]),axis=0)
X_train=np.concatenate((X_train0,X_train1,X_train2,X_train3,X_train4,X_train5),axis=0)
gmm = GaussianMixture(n_components=2)
gmm.fit(X_train)

print("Training Accuracies")
labels_rajesh = gmm.predict(X_train0)
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_train1)
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_train2)
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_train3)
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_train4)
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_train5)
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average training accuracy:",mean(x))
print("end")
print()

print("Test Accuracies")
labels_rajesh = gmm.predict(X_test[0])
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_test[1])
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_test[2])
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_test[3])
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_test[4])
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_test[5])
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average test accuracy:",mean(x))
print("end")

#Fold-3 cross validation

X_test=Train_part3
X_train0=np.concatenate((Train_part1[0],Train_part2[0],Train_part4[0],Train_part5[0]),axis=0)
X_train1=np.concatenate((Train_part1[1],Train_part2[1],Train_part4[1],Train_part5[1]),axis=0)
X_train2=np.concatenate((Train_part1[2],Train_part2[2],Train_part4[2],Train_part5[2]),axis=0)
X_train3=np.concatenate((Train_part1[3],Train_part2[3],Train_part4[3],Train_part5[3]),axis=0)
X_train4=np.concatenate((Train_part1[4],Train_part2[4],Train_part4[4],Train_part5[4]),axis=0)
X_train5=np.concatenate((Train_part1[5],Train_part2[5],Train_part4[5],Train_part5[5]),axis=0)
X_train=np.concatenate((X_train0,X_train1,X_train2,X_train3,X_train4,X_train5),axis=0)
gmm = GaussianMixture(n_components=2)
gmm.fit(X_train)

print("Training Accuracies")
labels_rajesh = gmm.predict(X_train0)
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_train1)
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_train2)
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_train3)
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_train4)
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_train5)
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average training accuracy:",mean(x))
print("end")
print()

print("Test Accuracies")
labels_rajesh = gmm.predict(X_test[0])
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_test[1])
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_test[2])
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_test[3])
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_test[4])
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_test[5])
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average test accuracy:",mean(x))
print("end")

#Fold-4 cross validation

X_test=Train_part4
X_train0=np.concatenate((Train_part1[0],Train_part2[0],Train_part3[0],Train_part5[0]),axis=0)
X_train1=np.concatenate((Train_part1[1],Train_part2[1],Train_part3[1],Train_part5[1]),axis=0)
X_train2=np.concatenate((Train_part1[2],Train_part2[2],Train_part3[2],Train_part5[2]),axis=0)
X_train3=np.concatenate((Train_part1[3],Train_part2[3],Train_part3[3],Train_part5[3]),axis=0)
X_train4=np.concatenate((Train_part1[4],Train_part2[4],Train_part3[4],Train_part5[4]),axis=0)
X_train5=np.concatenate((Train_part1[5],Train_part2[5],Train_part3[5],Train_part5[5]),axis=0)
X_train=np.concatenate((X_train0,X_train1,X_train2,X_train3,X_train4,X_train5),axis=0)
gmm = GaussianMixture(n_components=2)
gmm.fit(X_train)

print("Training Accuracies")
labels_rajesh = gmm.predict(X_train0)
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_train1)
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_train2)
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_train3)
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_train4)
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_train5)
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average training accuracy:",mean(x))
print("end")
print()

print("Test Accuracies")
labels_rajesh = gmm.predict(X_test[0])
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_test[1])
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_test[2])
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_test[3])
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_test[4])
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_test[5])
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average test accuracy:",mean(x))
print("end")

#Fold-5 cross validation

X_test=Train_part5
X_train0=np.concatenate((Train_part1[0],Train_part2[0],Train_part3[0],Train_part4[0]),axis=0)
X_train1=np.concatenate((Train_part1[1],Train_part2[1],Train_part3[1],Train_part4[1]),axis=0)
X_train2=np.concatenate((Train_part1[2],Train_part2[2],Train_part3[2],Train_part4[2]),axis=0)
X_train3=np.concatenate((Train_part1[3],Train_part2[3],Train_part3[3],Train_part4[3]),axis=0)
X_train4=np.concatenate((Train_part1[4],Train_part2[4],Train_part3[4],Train_part4[4]),axis=0)
X_train5=np.concatenate((Train_part1[5],Train_part2[5],Train_part3[5],Train_part4[5]),axis=0)
X_train=np.concatenate((X_train0,X_train1,X_train2,X_train3,X_train4,X_train5),axis=0)
gmm = GaussianMixture(n_components=2)
gmm.fit(X_train)

print("Training Accuracies")
labels_rajesh = gmm.predict(X_train0)
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_train1)
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_train2)
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_train3)
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_train4)
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_train5)
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average training accuracy:",mean(x))
print("end")
print()

print("Test Accuracies")
labels_rajesh = gmm.predict(X_test[0])
a=np.bincount(labels_rajesh.astype(int))

labels_manoj = gmm.predict(X_test[1])
b=np.bincount(labels_manoj.astype(int))

labels_vamsi = gmm.predict(X_test[2])
c=np.bincount(labels_vamsi.astype(int))

labels_sudheer = gmm.predict(X_test[3])
d=np.bincount(labels_sudheer.astype(int))

labels_daiveek=gmm.predict(X_test[4])
e=np.bincount(labels_daiveek.astype(int))

labels_imposter= gmm.predict(X_test[5])
f=np.bincount(labels_imposter.astype(int))

x=[]
x.append((np.max(a)/np.sum(a))*100)
x.append((np.max(b)/np.sum(b))*100)
x.append((np.max(c)/np.sum(c))*100)
x.append((np.max(d)/np.sum(d))*100)
x.append((np.max(e)/np.sum(e))*100)
x.append((np.max(f)/np.sum(f))*100)

print(a,x[0])
print(b,x[1])
print(c,x[2])
print(d,x[3])
print(e,x[4])
print(f,x[5])
print("average test accuracy:",mean(x))
print("end")



